## DATA SCIENCE PROJECTS | Gina Kim

##### Hello World! Welcome to my Data Science Portfolio page.
###### Connect with me on [Linkedin](https://www.linkedin.com/in/gina-kim-6625b88a/) or [Email](mailto:gaeun.gina.kim@gmail.com) me

#### [Project 1: Analysis on the Used Vehicle Price in the UK](https://github.com/k-gina/python_study/blob/main/studygroup_intermediate/analysis_on_used_vehicle_price.ipynb)
![](/images/projectimage1.png)
- Visualisation: used Matplotlib and Seaboarn libraries to visualise factors that have impacts on vehicle prices, such as mileage, age, make, and segment.
- Pre-processing data: used Sklearn for one-hot encoding and database normalization.
- Predictive Models: built Linear Regression and Polynomial Regression models to predict the price trends of used vehicles in the UK and test the accuracy of these models.
- Outcome: Polynomial regression model built and tested, with **95.24%** accuracy (R2). 


#### [Project 2: Analysis on Medicare Outpatient Data](https://github.com/k-gina/python_study/blob/main/studygroup_intermediate/medicare_data_analysis.ipynb)
![](/images/projectimage2.svg)
- Data: imported from Google Cloud Data.
- Visualisation: used Matplotlib and Seaborn libraries to plot bar chart for the most common outpatient conditions in the U.S. and then the average payments for these conditions per city.
- Pre-processing data: used Sklearn for database normalization.
- Clustering Analysis: used Sklearn to apply K-Means clustering algorithm. 
- Outcome: identified two clusters - the first group's average payment is 3.30 times more expensive than the second group, and the second group is 123.16 times bigger than the first group. i.e., 0.008 % of outpatient services costs more than triple compared to the rest of the services.


#### [Project 3: Venue Data Analysis of London](https://github.com/k-gina/python_study/blob/main/studygroup_intermediate/london_property_cluster_analysis.ipynb)
![](/images/projectimage3.png)
- Data: used Foursquare developer API to retrieve venue data information, and Beautiful Soup for web-scrapping London borough data on Wikipedia.
- Visualisation: used geopy.geocoders and Folium libraries to turn addresses into lat/long values and visualise clusters on a map. (* Please note that the map may not appear on the notebook hosted on the Github site as it is recognised as untrusted notebook.)
- Pre-processing data: used Sklearn for database normalization.
- Clustering Analysis: used Sklearn to apply K-Means clustering algorithm. 
- Outcome: successfully identified clusters of London venue data. 
